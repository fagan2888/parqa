{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "PARQA = os.getenv('PARQA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ontology = pd.read_csv(PARQA + 'parqa/311/ONTOLOGY/ontology/Ontology_verified2.csv')[['cleanName','NAME','Type','valid']]\n",
    "ontology= ontology[~ (ontology.valid=='?')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanName</th>\n",
       "      <th>NAME</th>\n",
       "      <th>Type</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>geo soilan park - battery park city</td>\n",
       "      <td>battery park city</td>\n",
       "      <td>other</td>\n",
       "      <td>av</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brookville park</td>\n",
       "      <td>brookville park</td>\n",
       "      <td>park_direct</td>\n",
       "      <td>av</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             cleanName               NAME         Type valid\n",
       "0  geo soilan park - battery park city  battery park city        other    av\n",
       "1                      brookville park    brookville park  park_direct    av"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ontology.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Ontology to DPR property data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ontology['pDistrict'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "park_direct    719\n",
       "pgs            368\n",
       "other          283\n",
       "empiric        209\n",
       "pool            60\n",
       "beach           12\n",
       "golf            12\n",
       "school           5\n",
       "recr             4\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ontology.Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## data for all types of keys in ontology\n",
    "dfs = {'park_direct': gp.read_file(PARQA + 'data/DPR_property/csv_ll_pD/' + 'parks_pd_ll_3.geojson' ),\n",
    "       'pgs': gp.read_file(PARQA + 'data/DPR_property/csv_ll_pD/' + 'playground_pd_ll.geojson' ),\n",
    "       'other': gp.read_file(PARQA + 'data/DPR_property/csv_ll_pD/' + 'parks_pd_ll_3.geojson' ),\n",
    "       'empiric': gp.read_file(PARQA + 'data/DPR_property/csv_ll_pD/' + 'parks_pd_ll_3.geojson' ),\n",
    "       'pool': gp.read_file(PARQA + 'data/DPR_property/csv_ll_pD/' + 'pools_pd_ll.geojson' ),\n",
    "       'beach': gp.read_file(PARQA + 'data/DPR_property/csv_ll_pD/' + 'beaches_pd_ll_2.geojson' ),\n",
    "       'golf': gp.read_file(PARQA + 'data/DPR_property/csv_ll_pD/' + 'golf_courses_pd_ll.geojson' ),\n",
    "       'school':gp.read_file(PARQA + 'data/DPR_property/csv_ll_pD/' + 'ps_pd_ll.geojson' ),\n",
    "       'recr': gp.read_file(PARQA + 'data/DPR_property/csv_ll_pD/' + 'recr_c_pd_ll.geojson' )}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school 0\n",
      "other 22\n",
      "empiric 22\n",
      "pgs 0\n",
      "recr 0\n",
      "golf 0\n",
      "beach 0\n",
      "pool 1\n",
      "park_direct 22\n"
     ]
    }
   ],
   "source": [
    "# how many datasets have unrecognised parkDistrict\n",
    "for key in dfs:\n",
    "    print key, len(dfs[key][pd.isnull(dfs[key].parkDistrict)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rename all naming columns to NAME\n",
    "\n",
    "dfs['school'] = dfs['school'].rename(columns={'PSID':'NAME'})\n",
    "dfs['other'] = dfs['other'].rename(columns={'SIGNNAME':'NAME'})\n",
    "dfs['empiric'] = dfs['empiric'].rename(columns={'SIGNNAME':'NAME'})\n",
    "dfs['pool'] = dfs['pool'].rename(columns={'Name':'NAME'})\n",
    "dfs['park_direct'] = dfs['park_direct'].rename(columns={'SIGNNAME':'NAME'})\n",
    "\n",
    "for key in dfs:\n",
    "    if 'NAME'not in dfs[key].columns:\n",
    "        print key,dfs[key].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lover all keys\n",
    "\n",
    "for item in dfs.values():\n",
    "    item['NAME'] = item.NAME.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mergePartial(df,dfs, key):\n",
    "    x = ontology.ix[ontology.Type==key, :].merge( dfs[key][['NAME','parkDistrict']], how='left', on='NAME', cop)\n",
    "    print k, x.columns\n",
    "    return  x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # check all failed merges\n",
    "# for k in dfs.keys():\n",
    "#     x = mergePartial(ontology, dfs, k)\n",
    "#     if len(x[pd.isnull(x.parkDistrict)])>0:\n",
    "#         print k, len(x[pd.isnull(x.parkDistrict)])\n",
    "#         print x[pd.isnull(x.parkDistrict)].NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in dfs.keys():\n",
    "    dfs[key]['Type'] = key\n",
    "    \n",
    "superduperDataFrame = pd.concat([dfs[key][['NAME','parkDistrict','Type','geometry']] for key in dfs.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# superduperDataFrame.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ontoMatched = ontology.merge(superduperDataFrame, how='left',on=['Type','NAME']) \n",
    "len(ontoMatched[pd.isnull(ontoMatched.geometry)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanName</th>\n",
       "      <th>NAME</th>\n",
       "      <th>Type</th>\n",
       "      <th>valid</th>\n",
       "      <th>parkDistrict_x</th>\n",
       "      <th>parkDistrict_y</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>geo soilan park - battery park city</td>\n",
       "      <td>battery park city</td>\n",
       "      <td>other</td>\n",
       "      <td>av</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M-01</td>\n",
       "      <td>POINT (-74.01689299366825 40.71188154925514)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>geo soilan park - battery park city</td>\n",
       "      <td>battery park city</td>\n",
       "      <td>other</td>\n",
       "      <td>av</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M-01</td>\n",
       "      <td>POINT (-74.01689047726609 40.71271929265585)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             cleanName               NAME   Type valid  \\\n",
       "0  geo soilan park - battery park city  battery park city  other    av   \n",
       "1  geo soilan park - battery park city  battery park city  other    av   \n",
       "\n",
       "  parkDistrict_x parkDistrict_y                                      geometry  \n",
       "0            NaN           M-01  POINT (-74.01689299366825 40.71188154925514)  \n",
       "1            NaN           M-01  POINT (-74.01689047726609 40.71271929265585)  "
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ontoMatched.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ontoMatched.to_csv(PARQA + 'parqa/311/ONTOLOGY/ontology/Ontology_matched.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
